{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "from langdetect import DetectorFactory, detect\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "def is_english(text):\n",
    "    try:\n",
    "        if detect(text) != \"en\":\n",
    "            return False\n",
    "    except LangDetectException:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def scrape_tweets(keyword_search:str, since_date:str, until_date:str):\n",
    "    tweets = []\n",
    "    for j, tweet in enumerate(sntwitter.TwitterSearchScraper(keyword_search+' since:'+since_date+' until:'+until_date).get_items()):\n",
    "#        if j>100000:\n",
    "#           break\n",
    "        tweets.append([tweet.date, tweet.id, tweet.content, tweet.user.username])\n",
    "    tweets_df = pd.DataFrame(tweets, columns=['Datetime', 'Tweet Id', 'Text', 'Username'])\n",
    "    tweets_df['language'] =  tweets_df['Text'].apply(is_english)\n",
    "    tweets_df = tweets_df[tweets_df['language'] == True].reset_index()\n",
    "    return tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error retrieving https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_ext_alt_text=true&include_quote_count=true&include_reply_count=1&tweet_mode=extended&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&send_error_codes=true&simple_quoted_tweets=true&q=transplant+since%3A2022-01-01+until%3A2022-07-07&tweet_search_mode=live&count=100&query_source=spelling_expansion_revert_click&cursor=scroll%3AthGAVUV0VFVBaCwKuV9KCP4CkWgIC8obTqrPAqEnEVn_6HARWAiXoYB0RFRkFVTFQ1ARX0qgEVAAA%3D&pc=1&spelling_corrections=1&ext=mediaStats%2ChighlightedLabel: ConnectionError(MaxRetryError(\"HTTPSConnectionPool(host='api.twitter.com', port=443): Max retries exceeded with url: /2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_ext_alt_text=true&include_quote_count=true&include_reply_count=1&tweet_mode=extended&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&send_error_codes=true&simple_quoted_tweets=true&q=transplant+since%3A2022-01-01+until%3A2022-07-07&tweet_search_mode=live&count=100&query_source=spelling_expansion_revert_click&cursor=scroll%3AthGAVUV0VFVBaCwKuV9KCP4CkWgIC8obTqrPAqEnEVn_6HARWAiXoYB0RFRkFVTFQ1ARX0qgEVAAA%3D&pc=1&spelling_corrections=1&ext=mediaStats%2ChighlightedLabel (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x000002A90EC8BA60>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))\"))\n",
      "4 requests to https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_ext_alt_text=true&include_quote_count=true&include_reply_count=1&tweet_mode=extended&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&send_error_codes=true&simple_quoted_tweets=true&q=transplant+since%3A2022-01-01+until%3A2022-07-07&tweet_search_mode=live&count=100&query_source=spelling_expansion_revert_click&cursor=scroll%3AthGAVUV0VFVBaCwKuV9KCP4CkWgIC8obTqrPAqEnEVn_6HARWAiXoYB0RFRkFVTFQ1ARX0qgEVAAA%3D&pc=1&spelling_corrections=1&ext=mediaStats%2ChighlightedLabel failed, giving up.\n"
     ]
    },
    {
     "ename": "ScraperException",
     "evalue": "4 requests to https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_ext_alt_text=true&include_quote_count=true&include_reply_count=1&tweet_mode=extended&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&send_error_codes=true&simple_quoted_tweets=true&q=transplant+since%3A2022-01-01+until%3A2022-07-07&tweet_search_mode=live&count=100&query_source=spelling_expansion_revert_click&cursor=scroll%3AthGAVUV0VFVBaCwKuV9KCP4CkWgIC8obTqrPAqEnEVn_6HARWAiXoYB0RFRkFVTFQ1ARX0qgEVAAA%3D&pc=1&spelling_corrections=1&ext=mediaStats%2ChighlightedLabel failed, giving up.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mScraperException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mUntitled-2.ipynb Cell 3'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#ch0000006untitled?line=0'>1</a>\u001b[0m tweets_df \u001b[39m=\u001b[39m scrape_tweets(\u001b[39m\"\u001b[39;49m\u001b[39mtransplant\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m2022-01-01\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m2022-07-07\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32mUntitled-2.ipynb Cell 2'\u001b[0m in \u001b[0;36mscrape_tweets\u001b[1;34m(keyword_search, since_date, until_date)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#ch0000002untitled?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mscrape_tweets\u001b[39m(keyword_search:\u001b[39mstr\u001b[39m, since_date:\u001b[39mstr\u001b[39m, until_date:\u001b[39mstr\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#ch0000002untitled?line=15'>16</a>\u001b[0m     tweets \u001b[39m=\u001b[39m []\n\u001b[1;32m---> <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#ch0000002untitled?line=16'>17</a>\u001b[0m     \u001b[39mfor\u001b[39;00m j, tweet \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(sntwitter\u001b[39m.\u001b[39mTwitterSearchScraper(keyword_search\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m since:\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39msince_date\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m until:\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39muntil_date)\u001b[39m.\u001b[39mget_items()):\n\u001b[0;32m     <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#ch0000002untitled?line=17'>18</a>\u001b[0m \u001b[39m#        if j>100000:\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#ch0000002untitled?line=18'>19</a>\u001b[0m \u001b[39m#           break\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#ch0000002untitled?line=19'>20</a>\u001b[0m         tweets\u001b[39m.\u001b[39mappend([tweet\u001b[39m.\u001b[39mdate, tweet\u001b[39m.\u001b[39mid, tweet\u001b[39m.\u001b[39mcontent, tweet\u001b[39m.\u001b[39muser\u001b[39m.\u001b[39musername])\n\u001b[0;32m     <a href='vscode-notebook-cell:Untitled-2.ipynb?jupyter-notebook#ch0000002untitled?line=20'>21</a>\u001b[0m     tweets_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(tweets, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mDatetime\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mTweet Id\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mText\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mUsername\u001b[39m\u001b[39m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Woon.Kim\\Anaconda33\\lib\\site-packages\\snscrape\\modules\\twitter.py:680\u001b[0m, in \u001b[0;36mTwitterSearchScraper.get_items\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    677\u001b[0m \t\u001b[39mdel\u001b[39;00m params[\u001b[39m'\u001b[39m\u001b[39mtweet_search_mode\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m    678\u001b[0m \t\u001b[39mdel\u001b[39;00m paginationParams[\u001b[39m'\u001b[39m\u001b[39mtweet_search_mode\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m--> 680\u001b[0m \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter_api_data(\u001b[39m'\u001b[39m\u001b[39mhttps://api.twitter.com/2/search/adaptive.json\u001b[39m\u001b[39m'\u001b[39m, params, paginationParams, cursor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cursor):\n\u001b[0;32m    681\u001b[0m \t\u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_instructions_to_tweets(obj)\n",
      "File \u001b[1;32mc:\\Users\\Woon.Kim\\Anaconda33\\lib\\site-packages\\snscrape\\modules\\twitter.py:369\u001b[0m, in \u001b[0;36m_TwitterAPIScraper._iter_api_data\u001b[1;34m(self, endpoint, params, paginationParams, cursor, direction)\u001b[0m\n\u001b[0;32m    367\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    368\u001b[0m \t_logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mRetrieving scroll page \u001b[39m\u001b[39m{\u001b[39;00mcursor\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 369\u001b[0m \tobj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_api_data(endpoint, reqParams)\n\u001b[0;32m    370\u001b[0m \t\u001b[39myield\u001b[39;00m obj\n\u001b[0;32m    372\u001b[0m \t\u001b[39m# No data format test, just a hard and loud crash if anything's wrong :-)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Woon.Kim\\Anaconda33\\lib\\site-packages\\snscrape\\modules\\twitter.py:339\u001b[0m, in \u001b[0;36m_TwitterAPIScraper._get_api_data\u001b[1;34m(self, endpoint, params)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_api_data\u001b[39m(\u001b[39mself\u001b[39m, endpoint, params):\n\u001b[0;32m    338\u001b[0m \t\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ensure_guest_token()\n\u001b[1;32m--> 339\u001b[0m \tr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get(endpoint, params \u001b[39m=\u001b[39;49m params, headers \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apiHeaders, responseOkCallback \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_api_response)\n\u001b[0;32m    340\u001b[0m \t\u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    341\u001b[0m \t\tobj \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[1;32mc:\\Users\\Woon.Kim\\Anaconda33\\lib\\site-packages\\snscrape\\base.py:216\u001b[0m, in \u001b[0;36mScraper._get\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 216\u001b[0m \t\u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_request(\u001b[39m'\u001b[39m\u001b[39mGET\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Woon.Kim\\Anaconda33\\lib\\site-packages\\snscrape\\base.py:212\u001b[0m, in \u001b[0;36mScraper._request\u001b[1;34m(self, method, url, params, data, headers, timeout, responseOkCallback, allowRedirects)\u001b[0m\n\u001b[0;32m    210\u001b[0m \tmsg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retries \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m requests to \u001b[39m\u001b[39m{\u001b[39;00mreq\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m failed, giving up.\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    211\u001b[0m \tlogger\u001b[39m.\u001b[39mfatal(msg)\n\u001b[1;32m--> 212\u001b[0m \t\u001b[39mraise\u001b[39;00m ScraperException(msg)\n\u001b[0;32m    213\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mReached unreachable code\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mScraperException\u001b[0m: 4 requests to https://api.twitter.com/2/search/adaptive.json?include_profile_interstitial_type=1&include_blocking=1&include_blocked_by=1&include_followed_by=1&include_want_retweets=1&include_mute_edge=1&include_can_dm=1&include_can_media_tag=1&skip_status=1&cards_platform=Web-12&include_cards=1&include_ext_alt_text=true&include_quote_count=true&include_reply_count=1&tweet_mode=extended&include_entities=true&include_user_entities=true&include_ext_media_color=true&include_ext_media_availability=true&send_error_codes=true&simple_quoted_tweets=true&q=transplant+since%3A2022-01-01+until%3A2022-07-07&tweet_search_mode=live&count=100&query_source=spelling_expansion_revert_click&cursor=scroll%3AthGAVUV0VFVBaCwKuV9KCP4CkWgIC8obTqrPAqEnEVn_6HARWAiXoYB0RFRkFVTFQ1ARX0qgEVAAA%3D&pc=1&spelling_corrections=1&ext=mediaStats%2ChighlightedLabel failed, giving up."
     ]
    }
   ],
   "source": [
    "tweets_df = scrape_tweets(\"transplant\", \"2022-01-01\", \"2022-07-07\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>2022-07-06 23:28:09+00:00</td>\n",
       "      <td>1544825559498244102</td>\n",
       "      <td>@TheDemocrats @MeidasTouch They will never giv...</td>\n",
       "      <td>cathy_venus</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>2022-07-06 23:20:20+00:00</td>\n",
       "      <td>1544823591463751683</td>\n",
       "      <td>@karisferg I hope you get the chance, it’s cool</td>\n",
       "      <td>cathy_venus</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>2022-07-06 22:04:02+00:00</td>\n",
       "      <td>1544804388761370631</td>\n",
       "      <td>CMV- a (white tee) par 3 should be reachable f...</td>\n",
       "      <td>FoGOLF</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>2022-07-06 20:39:03+00:00</td>\n",
       "      <td>1544783004828139522</td>\n",
       "      <td>We are excited to announce the detailed agenda...</td>\n",
       "      <td>EHDIconference</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>2022-07-06 20:38:01+00:00</td>\n",
       "      <td>1544782745993445381</td>\n",
       "      <td>We are excited to announce the detailed agenda...</td>\n",
       "      <td>InfantHearing</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                  Datetime             Tweet Id  \\\n",
       "0     14 2022-07-06 23:28:09+00:00  1544825559498244102   \n",
       "1     16 2022-07-06 23:20:20+00:00  1544823591463751683   \n",
       "2     40 2022-07-06 22:04:02+00:00  1544804388761370631   \n",
       "3     52 2022-07-06 20:39:03+00:00  1544783004828139522   \n",
       "4     53 2022-07-06 20:38:01+00:00  1544782745993445381   \n",
       "\n",
       "                                                Text        Username  language  \n",
       "0  @TheDemocrats @MeidasTouch They will never giv...     cathy_venus      True  \n",
       "1    @karisferg I hope you get the chance, it’s cool     cathy_venus      True  \n",
       "2  CMV- a (white tee) par 3 should be reachable f...          FoGOLF      True  \n",
       "3  We are excited to announce the detailed agenda...  EHDIconference      True  \n",
       "4  We are excited to announce the detailed agenda...   InfantHearing      True  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to roberta-large-mnli (https://huggingface.co/roberta-large-mnli)\n",
      "All model checkpoint layers were used when initializing TFRobertaForSequenceClassification.\n",
      "\n",
      "All the layers of TFRobertaForSequenceClassification were initialized from the model checkpoint at roberta-large-mnli.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaForSequenceClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': '@karisferg I hope you get the chance, it’s cool',\n",
       " 'labels': ['care',\n",
       "  'burden',\n",
       "  'financial',\n",
       "  'transplant',\n",
       "  'maribavir',\n",
       "  'health care'],\n",
       " 'scores': [0.37932509183883667,\n",
       "  0.32932835817337036,\n",
       "  0.10205322504043579,\n",
       "  0.09276972711086273,\n",
       "  0.05484664812684059,\n",
       "  0.04167698696255684]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "\n",
    "classifier(\n",
    "\n",
    "    tweets_df['Text'][1],\n",
    "\n",
    "    candidate_labels=[\"transplant\", \"maribavir\", \"health care\", \"burden\", \"care\", \"financial\"],\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We are excited to announce the detailed agenda for the 2022 CMV Public Health and Policy Conference is now posted. View the agenda at https://t.co/DiXF1Q6AY2. Register by July 15 to save on costs. We look forward to seeing you in Ottawa for this one-of-a-kind conference! https://t.co/HQiNw6lLF8'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df['Text'][3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "723860b9bcb0b1e72b55ae11883eb093fb3432a85486e4dad0490b6a92cc27fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
