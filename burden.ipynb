{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_burden = pd.read_csv('data_2020.csv')\n",
    "data_burden = data_burden[data_burden['burden'].notna()]\n",
    "data_burden = data_burden[data_burden.columns[data_burden.isnull().mean() < 0.2]]\n",
    "\n",
    "data_burden.columns[data_burden.isnull().any()]\n",
    "\n",
    "for column in data_burden.columns:\n",
    "    data_burden[column].fillna(data_burden[column].mode()[0], inplace=True)\n",
    "\n",
    "median = data_burden.loc[data_burden['agecr'] < 200, 'agecr'].median()\n",
    "data_burden[\"agecr\"] = np.where(data_burden[\"agecr\"] > 200, median,data_burden['agecr'])\n",
    "\n",
    "# random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_feature = data_burden.drop('burden', axis = 1)\n",
    "y_feature = data_burden['burden']\n",
    "\n",
    "#m = sqrt(p)+1 features\n",
    "nfeatures = data_burden.shape[1] - 1\n",
    "feature_model = RandomForestRegressor(max_features = int(np.sqrt(nfeatures))+1, random_state = 1) #random_state ensure random bagging\n",
    "feature_model.fit(X_feature,y_feature)\n",
    "\n",
    "\n",
    "df_feature = pd.DataFrame(zip(X_feature.columns, feature_model.feature_importances_), columns = ['feature','importance'])\n",
    "df_feature = df_feature.sort_values(by=['importance'], ascending=False)\n",
    "\n",
    "df_feature[0:29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = df_feature[0:19], x = 'importance', y='feature', orient = 'h');\n",
    "plt.title('Feature Importance Plot Random Forest')\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the top few of the high important features while avoiding multi-colinearity\n",
    "data_burden = data_burden[['year', 'Q18', 'HOURS', 'adls', 'q22a', 'q22b', 'q22d', 'N3', 'q22c', 'iadls', 'q22g', 'q22f', 'q23d', 'banlives', 'q23c', 'q22e', 'burden']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#See the tally of data points of each of the illnesses\n",
    "data_burden.groupby(['Q18'])['Q18'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the only the ones with sufficient datapoints --- 80+ was arbitrarily chosen \n",
    "lst = [24.0, 3.0, 23.0, 32.0, 14.0, 22.0, 19.0, 30.0, 16.0, 8.0, 18.0, 5.0, 20.0, 13.0, 43.0]\n",
    "data_burden = data_burden.loc[data_burden['Q18'].isin(lst)]\n",
    "data_burden[\"Q18\"] = data_burden[\"Q18\"].astype(str)\n",
    "\n",
    "#re-code the numbers to actual illness\n",
    "data_burden[\"Q18\"] = data_burden[\"Q18\"].replace([\"3.0\",\"5.0\",\"8.0\",\"14.0\",\"16.0\",\"18.0\",\"19.0\",\"20.0\",\"22.0\",\"23.0\",\"24.0\",\"30.0\",\"32.0\"\n",
    "                           , \"13.0\", '43.0'], [\"Alzheimer\",\"Arthritis\", \"BackProblems\"\n",
    "                           ,\"Cancer\", \"Diabetes\", \"Falling\", \"HeartDisease\",\n",
    "                            \"LungDisease\", \"MentalIllness\", \"MobilityProblem\", \"Aging\",  \"Stroke\",\n",
    "                            \"Surgery\", \"BrokenBones\", \"Alzheimer\"])\n",
    "data_burden.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change the data types to categorical\n",
    "lst2 = ['q22a', 'q22b', 'q22d', 'N3', 'q22c', 'q22g', 'q22f', 'q23d', 'banlives', 'q23c', 'q22e']\n",
    "data_burden[lst2] = data_burden[lst2].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove useless values such as \"don't know\", \"not answered\"\n",
    "\n",
    "values = [3.0, 4.0]\n",
    "data_burden = data_burden[\n",
    "    (data_burden.q22a.isin(values) == False) \\\n",
    "        & (data_burden.q22b.isin(values) == False) \\\n",
    "        & (data_burden.q22d.isin(values) == False)\n",
    "        & (data_burden.N3.isin(values) == False) \\\n",
    "        & (data_burden.q22c.isin(values) == False) \\\n",
    "        & (data_burden.q22g.isin(values) == False) \\\n",
    "        & (data_burden.q22f.isin(values) == False) \\\n",
    "        & (data_burden.q23d.isin(values) == False) \\\n",
    "        & (data_burden.q23c.isin(values) == False) \\\n",
    "        & (data_burden.q22e.isin(values) == False)                        \n",
    "                        ]\n",
    "\n",
    "data_burden = data_burden[data_burden['banlives'] != 3.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_burden.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-coding survey numbers to actual response\n",
    "data_burden[\"q22a\"] = data_burden[\"q22a\"].astype(str)\n",
    "data_burden[\"q22a\"] = data_burden[\"q22a\"].replace([\"1.0\",\"2.0\"], [\"Yes\",\"No\"])\n",
    "data_burden[\"q22b\"] = data_burden[\"q22b\"].astype(str)\n",
    "data_burden[\"q22b\"] = data_burden[\"q22b\"].replace([\"1.0\",\"2.0\"], [\"Yes\",\"No\"])\n",
    "data_burden[\"q22d\"] = data_burden[\"q22d\"].astype(str)\n",
    "data_burden[\"q22d\"] = data_burden[\"q22d\"].replace([\"1.0\",\"2.0\"], [\"Yes\",\"No\"])\n",
    "data_burden[\"N3\"] = data_burden[\"N3\"].astype(str)\n",
    "data_burden[\"N3\"] = data_burden[\"N3\"].replace([\"1.0\",\"2.0\"], [\"Yes\",\"No\"])\n",
    "data_burden[\"q22c\"] = data_burden[\"q22c\"].astype(str)\n",
    "data_burden[\"q22c\"] = data_burden[\"q22c\"].replace([\"1.0\",\"2.0\"], [\"Yes\",\"No\"])\n",
    "data_burden[\"q22g\"] = data_burden[\"q22g\"].astype(str)\n",
    "data_burden[\"q22g\"] = data_burden[\"q22g\"].replace([\"1.0\",\"2.0\"], [\"Yes\",\"No\"])\n",
    "data_burden[\"q22f\"] = data_burden[\"q22f\"].astype(str)\n",
    "data_burden[\"q22f\"] = data_burden[\"q22f\"].replace([\"1.0\",\"2.0\"], [\"Yes\",\"No\"])\n",
    "data_burden[\"q23d\"] = data_burden[\"q23d\"].astype(str)\n",
    "data_burden[\"q23d\"] = data_burden[\"q23d\"].replace([\"1.0\",\"2.0\"], [\"Yes\",\"No\"])\n",
    "data_burden[\"q23c\"] = data_burden[\"q23c\"].astype(str)\n",
    "data_burden[\"q23c\"] = data_burden[\"q23c\"].replace([\"1.0\",\"2.0\"], [\"Yes\",\"No\"])\n",
    "data_burden[\"q22e\"] = data_burden[\"q22e\"].astype(str)\n",
    "data_burden[\"q22e\"] = data_burden[\"q22e\"].replace([\"1.0\",\"2.0\"], [\"Yes\",\"No\"])\n",
    "\n",
    "data_burden[\"banlives\"] = data_burden[\"banlives\"].astype(str)\n",
    "data_burden[\"banlives\"] = data_burden[\"banlives\"].replace([\"1.0\",\"2.0\"], [\"Yes\",\"No\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming the column names to laymens terms\n",
    "data_burden.columns = ['year', 'illness', 'hours', 'adls', 'help_with_bed', 'help_with_dressed', 'help_with_bathe', 'help_with_med', 'help_with_toilet', 'iadls', 'giving_medicine', 'help_with_feeding', 'preparing_meals', 'live_with_cr', 'help_housework', 'help_with_diapers', 'burden']\n",
    "data_burden = data_burden.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df_1 = data_burden.groupby(['illness'])['burden'].median()\n",
    "df_1 = df_1.to_frame()\n",
    "df_1.reset_index(inplace=True)\n",
    "df_1 = df_1.rename(columns = {'index':'illness'})\n",
    "df_1['illness'] = df_1['illness'].astype(object)\n",
    "\n",
    "fig = plt.figure(1, [20, 8])\n",
    "fig.clf()\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlim(-1,14)\n",
    "plt.setp(ax.get_xticklabels(), fontsize=10, rotation='vertical')\n",
    "plt.bar(df_1['illness'],df_1['burden'])\n",
    "\n",
    "plt.axhline(y=(df_1[df_1['illness'] == 'Aging']['burden'][0]),linewidth= 3, color='r', linestyle= 'dotted')\n",
    "plt.title(label = \"burden\", fontsize=40)\n",
    "plt.plot()\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sns.catplot(x=\"burden\", y=\"help_with_diapers\", kind=\"box\", data=data_2014)\n",
    "sns.catplot(x=\"help_with_diapers\", y=\"burden\", kind=\"box\", data=data_2014)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_burden.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.catplot(x=\"burden\", y=\"hours\", kind=\"box\", data=data_burden)\n",
    "sns.catplot(x=\"burden\", y=\"hours\", kind=\"violin\", data=data_burden)\n",
    "\n",
    "#sns.catplot(x=\"burden\", y=\"iadls\", kind=\"box\", data=data_burden)\n",
    "sns.catplot(x=\"burden\", y=\"iadls\", kind=\"violin\", data=data_burden)\n",
    "\n",
    "#sns.catplot(x=\"burden\", y=\"adls\", kind=\"box\", data=data_burden)\n",
    "sns.catplot(x=\"burden\", y=\"adls\", kind=\"violin\", data=data_burden)\n",
    "\n",
    "#sns.catplot(x=\"help_with_bed\", y=\"burden\", kind=\"box\", data=data_burden)\n",
    "sns.catplot(x=\"help_with_bed\", y=\"burden\", kind=\"violin\", data=data_burden, order=[\"Yes\", \"No\"])\n",
    "\n",
    "#sns.catplot(x=\"help_with_dressed\", y=\"burden\", kind=\"box\", data=data_burden)\n",
    "sns.catplot(x=\"help_with_dressed\", y=\"burden\", kind=\"violin\", data=data_burden, order=[\"Yes\", \"No\"])\n",
    "\n",
    "#sns.catplot(x=\"help_with_bathe\", y=\"burden\", kind=\"box\", data=data_burden)\n",
    "sns.catplot(x=\"help_with_bathe\", y=\"burden\", kind=\"violin\", data=data_burden, order=[\"Yes\", \"No\"])\n",
    "\n",
    "#sns.catplot(x=\"help_with_med\", y=\"burden\", kind=\"box\", data=data_burden)\n",
    "sns.catplot(x=\"help_with_med\", y=\"burden\", kind=\"violin\", data=data_burden, order=[\"Yes\", \"No\"])\n",
    "\n",
    "#sns.catplot(x=\"help_with_toilet\", y=\"burden\", kind=\"box\", data=data_burden)\n",
    "sns.catplot(x=\"help_with_toilet\", y=\"burden\", kind=\"violin\", data=data_burden, order=[\"Yes\", \"No\"])\n",
    "\n",
    "#sns.catplot(x=\"giving_medicine\", y=\"burden\", kind=\"box\", data=data_burden)\n",
    "sns.catplot(x=\"giving_medicine\", y=\"burden\", kind=\"violin\", data=data_burden, order=[\"Yes\", \"No\"])\n",
    "#sns.boxplot(x='species', y='sepal_length', data=df, order=[\"versicolor\", \"virginica\", \"setosa\"])\n",
    "\n",
    "#sns.catplot(x=\"help_with_feeding\", y=\"burden\", kind=\"box\", data=data_burden)\n",
    "sns.catplot(x=\"help_with_feeding\", y=\"burden\", kind=\"violin\", data=data_burden, order=[\"Yes\", \"No\"])\n",
    "\n",
    "#sns.catplot(x=\"preparing_meals\", y=\"burden\", kind=\"box\", data=data_burden)\n",
    "sns.catplot(x=\"preparing_meals\", y=\"burden\", kind=\"violin\", data=data_burden, order=[\"Yes\", \"No\"])\n",
    "\n",
    "#sns.catplot(x=\"live_with_cr\", y=\"burden\", kind=\"box\", data=data_burden)\n",
    "sns.catplot(x=\"live_with_cr\", y=\"burden\", kind=\"violin\", data=data_burden, order=[\"Yes\", \"No\"])\n",
    "\n",
    "#sns.catplot(x=\"help_housework\", y=\"burden\", kind=\"box\", data=data_burden)\n",
    "sns.catplot(x=\"help_housework\", y=\"burden\", kind=\"violin\", data=data_burden, order=[\"Yes\", \"No\"])\n",
    "\n",
    "#sns.catplot(x=\"help_with_diapers\", y=\"burden\", kind=\"box\", data=data_burden)\n",
    "sns.catplot(x=\"help_with_diapers\", y=\"burden\", kind=\"violin\", data=data_burden, order=[\"Yes\", \"No\"])\n",
    "\n",
    "\n",
    "\n",
    "sns.catplot(x=\"burden\", y=\"illness\",\n",
    "            kind=\"violin\", data=data_burden)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2015 = data_burden[data_burden['year'] == 2014]\n",
    "data_2020 = data_burden[data_burden['year'] == 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2015.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2015.groupby(['illness'])['burden'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2020.groupby(['illness'])['burden'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"burden\", y=\"illness\",\n",
    "            kind=\"violin\", data=data_2015)\n",
    "\n",
    "sns.catplot(x=\"burden\", y=\"illness\",\n",
    "            kind=\"violin\", data=data_2020, order=[\"Aging\", \"MobilityProblem\", \"Arthritis\", \"Cancer\", \"Diabetes\", \"MentalIllness\", \"Alzheimer\", \"Surgery\", \"HeartDisease\", \"Stroke\", \"BackProblems\", \"BrokenBones\", \"LungDisease\", \"Falling\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Narrow Down Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping features with small correlations\n",
    "data_burden2 = data_burden.drop(['adls', 'help_housework', 'live_with_cr', 'preparing_meals', 'giving_medicine', 'help_with_med'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the continuous variables and the categorical variables \n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "df_cont2 = data_burden2.select_dtypes(include=numerics)\n",
    "df_cat2 = data_burden2.select_dtypes(include = 'object')\n",
    "\n",
    "#dummy coding the categorical variables\n",
    "df_cat_dc2 = pd.get_dummies(df_cat2)\n",
    "df_reg2 = pd.concat([df_cont2, df_cat_dc2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function for 10-CV\n",
    "# 10-Fold Cross Validation\n",
    "def cross_validation (df, func):\n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = KFold(n_splits = 10, shuffle = True, random_state = 10)\n",
    "    kf_rmse = []\n",
    "    \n",
    "    for train, test in kf.split(df):\n",
    "        X_train = df.iloc[train].loc[:, df.columns != 'burden']\n",
    "        X_train = X_train.squeeze()\n",
    "        X_test = df.iloc[test].loc[:, df.columns != 'burden']\n",
    "        y_train = df.iloc[train].loc[:,'burden']\n",
    "        y_test = df.iloc[test].loc[:,'burden']\n",
    "        \n",
    "        reg = func.fit(X_train, y_train)\n",
    "        y_hat = reg.predict(X_test)\n",
    "        \n",
    "        from sklearn.metrics import mean_squared_error\n",
    "        kf_rmse.append(mean_squared_error(y_test, y_hat, squared=False))\n",
    "        \n",
    "    kf_RMSE = (1/10) * np.sum(kf_rmse)\n",
    "        \n",
    "    return (kf_RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use 2014 data as train and 2020 data as test\n",
    "X_train2 = df_reg2[df_reg2['year'] == 2014]\n",
    "y_train2 = X_train2['burden']\n",
    "X_train2 = X_train2.drop('burden', axis = 1)\n",
    "df_train2 = pd.concat([X_train2, y_train2], axis=1, join='outer')\n",
    "\n",
    "X_test2 = df_reg2[df_reg2['year'] == 2019]\n",
    "y_test2 = X_test2['burden']\n",
    "X_test2 = X_test2.drop('burden', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with Narrowed Down Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model1 = LinearRegression()\n",
    "\n",
    "model1.fit(X_train2, y_train2)\n",
    "\n",
    "y_hat11 = model1.predict(X_test2)\n",
    "\n",
    "score11 = np.mean(cross_val_score(estimator = model1, X = X_train2, y = y_train2, cv = 10))\n",
    "model11_train_rmse = mean_squared_error(y_test2, y_hat11, squared=False)\n",
    "model11_cv_rmse = cross_validation(df_reg2, model1)\n",
    "\n",
    "print('test RMSE = ', model11_train_rmse)\n",
    "print('10 CV RMSE = ', model11_cv_rmse)\n",
    "print('score = ', score11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.scatter(x = y_test2, y = y_hat11, s = 8, label = \"Test\")\n",
    "plt.scatter(x = y_train2, y = model1.predict(X_train2), s = 8, label = \"Train\")\n",
    "plt.scatter(x = df_reg2['burden'], y = df_reg2['burden'], s = 8, label = \"True\")\n",
    "plt.plot([0,6], [0,6], color = \"r\")\n",
    "plt.legend(loc=0)\n",
    "plt.title(\"Predicted Value vs True Value for Linear Regression\")\n",
    "plt.xlabel(\"True Value\")\n",
    "plt.ylabel(\"Predicted Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest with Narrowed Down Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomForest = RandomForestRegressor(random_state = 0)\n",
    "grid_para_forest = {'n_estimators': [100,500,1000,2500,5000],\n",
    "'max_depth': [10,15,20,30,40,50],\n",
    "'max_features' : [5,7,15]}\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "grid_search_forest = GridSearchCV(randomForest, grid_para_forest, cv=10, n_jobs = 5, verbose=1)\n",
    "grid_search_forest.fit(X_train2, y_train2)\n",
    "\n",
    "model2_2 = grid_search_forest.best_estimator_\n",
    "yhat_2_2 = model2_2.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_2_train_rmse = mean_squared_error(y_test2, yhat_2_2, squared=False)\n",
    "model2_2_cv_rmse = cross_validation(df_reg2, model2_2)\n",
    "score2_2 = np.mean(cross_val_score(estimator = model2_2, X = X_train2, y = y_train2, cv = 10))\n",
    "\n",
    "print('test RMSE = ', model2_2_train_rmse)\n",
    "print('10 CV RMSE = ', model2_2_cv_rmse)\n",
    "print('score = ', score2_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.scatter(x = y_test2, y = yhat_2_2, s = 8, label = \"Test\")\n",
    "plt.scatter(x = y_train2, y = model2_2.predict(X_train2), s = 8, label = \"Train\")\n",
    "plt.scatter(x = df_reg2['burden'], y = df_reg2['burden'], s = 8, label = \"True\")\n",
    "plt.plot([0,6], [0,6], color = \"r\")\n",
    "plt.legend(loc=0)\n",
    "plt.title(\"Predicted Value vs True Value for Random Forest\")\n",
    "plt.xlabel(\"True Value\")\n",
    "plt.ylabel(\"Predicted Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_importance = sorted(zip(df_reg2.drop('burden', axis = 1).columns, model2_2.feature_importances_), key=lambda t:t[1], reverse = True)\n",
    "a, b = zip(*sorted_importance)\n",
    "plt.figure(figsize = (10,10))\n",
    "df = pd.DataFrame({'feature_name':a, 'importance_score':b})\n",
    "sns.barplot(data = df, x = 'importance_score', y='feature_name', orient = 'h');\n",
    "plt.title('Feature Importance Plot Random Forest')\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the Random Forest Again with Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_cols = df[df['importance_score'] > 0.004]['feature_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_forest.fit(X_train2[imp_cols], y_train2)\n",
    "\n",
    "model22_2 = grid_search_forest.best_estimator_\n",
    "yhat_22_2 = model22_2.predict(X_test2[imp_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model22_2_train_rmse = mean_squared_error(y_test2, yhat_22_2, squared=False)\n",
    "model22_2_cv_rmse = cross_validation(df_reg2, model22_2)\n",
    "score22_2 = np.mean(cross_val_score(estimator = model22_2, X = X_train2, y = y_train2, cv = 10))\n",
    "\n",
    "print('test RMSE = ', model22_2_train_rmse)\n",
    "print('10 CV RMSE = ', model22_2_cv_rmse)\n",
    "print('score = ', score22_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.scatter(x = y_test2, y = yhat_22_2, s = 8, label = \"Test\")\n",
    "plt.scatter(x = y_train2, y = model22_2.predict(X_train2), s = 8, label = \"Train\")\n",
    "plt.scatter(x = df_reg2['burden'], y = df_reg2['burden'], s = 8, label = \"True\")\n",
    "plt.plot([0,6], [0,6], color = \"r\")\n",
    "plt.legend(loc=0)\n",
    "plt.title(\"Predicted Value vs True Value for Random Forest 2\")\n",
    "plt.xlabel(\"True Value\")\n",
    "plt.ylabel(\"Predicted Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "gbm = GradientBoostingRegressor(random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_para_gb = {'n_estimators': [100,500,1000,2500,5000],\n",
    "                   'learning_rate':[0.01,0.05,0.1],\n",
    "                   'max_depth':range(1,6),\n",
    "                   'max_features' : [5,7,15]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "grid_search_gb = GridSearchCV(gbm, grid_para_gb, cv=5, n_jobs = 5, verbose = 1)\n",
    "grid_search_gb.fit(X_train2, y_train2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = grid_search_gb.best_estimator_\n",
    "yhat_3 = model3.predict(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3_train_rmse = mean_squared_error(y_test2, yhat_3, squared=False)\n",
    "model3_cv_rmse = cross_validation(df_reg2, model3)\n",
    "score3 = np.mean(cross_val_score(estimator = model1, X = X_train2, y = y_train2, cv = 10))\n",
    "\n",
    "print('train RMSE = ', model3_train_rmse)\n",
    "print('10 CV RMSE = ', model3_cv_rmse)\n",
    "print('score = ', score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(x = y_test2, y = yhat_3, s = 8, label = \"Test\")\n",
    "plt.scatter(x = y_train2, y = model3.predict(X_train2), s = 8, label = \"Train\")\n",
    "plt.scatter(x = df_reg2['burden'], y = df_reg2, s = 8, label = \"True\")\n",
    "plt.plot([-2,8],[-2,8], color = \"r\")\n",
    "plt.legend(loc = 0)\n",
    "plt.title(\"Predicted Value vs True Value for Gradient Boost\")\n",
    "plt.xlabel(\"True Value\")\n",
    "plt.ylabel(\"Predicted Value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_importance = sorted(zip(df_reg2.columns, model3.feature_importances_), key=lambda t:t[1], reverse=True)\n",
    "a, b = zip(*sorted_importance)\n",
    "plt.figure(figsize = (10,10))\n",
    "df = pd.DataFrame({'feature_name':a, 'importance_score':b})\n",
    "sns.barplot(data = df, x = 'importance_score', y= 'feature_name', orient = 'h');\n",
    "plt.title('Feature Importance Plot Gradient Boosting')\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_cols = df[df['importance_score'] > 0.004]['feature_name'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_gb.fit(X_train2[imp_cols], y_train2)\n",
    "\n",
    "model33 = grid_search_gb.best_estimator_\n",
    "yhat_33 = model33.predict(X_test2[imp_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model33_train_rmse = mean_squared_error(y_test2, yhat_33, squared=False)\n",
    "model33_cv_rmse = cross_validation(df_reg2, model33)\n",
    "score33 = np.mean(cross_val_score(estimator = model33, X = X_train2, y = y_train2, cv = 10))\n",
    "\n",
    "print('train RMSE = ', model33_train_rmse)\n",
    "print('10 CV RMSE = ', model33_cv_rmse)\n",
    "print('score = ', score33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(x = y_test2, y = yhat_33, s = 8, label = \"Test\")\n",
    "plt.scatter(x = y_train2, y = model33.predict(X_train2), s = 8, label = \"Train\")\n",
    "plt.scatter(x = df_reg2['burden'], y = df_reg2, s = 8, label = \"True\")\n",
    "plt.plot([-2,8],[-2,8], color = \"r\")\n",
    "plt.legend(loc = 0)\n",
    "plt.title(\"Predicted Value vs True Value for Gradient Boost\")\n",
    "plt.xlabel(\"True Value\")\n",
    "plt.ylabel(\"Predicted Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RMSE Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['LinReg', 'RandomForest1', 'RandomForest2', 'GB1', 'GB2']\n",
    "y1 = [model11_train_rmse, model2_2_train_rmse, model22_2_train_rmse, model3_train_rmse, model33_train_rmse]\n",
    "y2 = [model11_cv_rmse, model2_2_cv_rmse, model22_2_cv_rmse, model3_cv_rmse, model33_cv_rmse]\n",
    "\n",
    "plt.plot(x, y2, label = \"10-CV RMSE\", c='r')\n",
    "plt.plot(x, y1, label = \"Train RMSE\", c='b')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = ['LinReg', 'RandomForest1', 'RandomForest2', 'GB1', 'GB2']\n",
    "y1 = [score11, score2_2, score22_2, score3, score33]\n",
    "\n",
    "plt.plot(x, y1, label = \"10-CV Score\", c='b')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "723860b9bcb0b1e72b55ae11883eb093fb3432a85486e4dad0490b6a92cc27fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
